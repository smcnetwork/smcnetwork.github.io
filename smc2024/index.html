
<!DOCTYPE html>
<html lang="en" id="page">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SMC 2024</title>
    <link href="css/reset.css" rel="stylesheet">
  	<link rel="preconnect" href="https://fonts.googleapis.com"> 
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,700;1,400;1,700&family=Raleway:wght@400;600&display=swap" rel="stylesheet">
    <link href="css/smc2024_v3.css" rel="stylesheet">
  </head>
  <body>
  
  <header>
    <section id="header" class="a"><div class="inner">
    <img src="imagens/immersive-vector_v2_branco.png" alt="SMC2024 logo">
    <h2>SMC 2024 / 4–6 July / ESMAE, Porto, Portugal</h2>
    <nav>
    <ul>
      <li><a href="#call_papers">Call for Papers</a></li>
      <li><a href="#call_music">Call for Music & Sonic Art</a></li>
      <li><a href="#submit">Important Dates</a></li>
      <li><a href="#registration">Registration</a></li>
    </ul>
    <br>
    <ul>
      <li><a href="#summer_school">Summer School</a></li>
      <li><a href="#keynote_speakers">Keynote Speakers</a></li>
      <li><a href="#committees">Committees</a></li>
      <li><a href="#location">Location</a></li>
    </ul>
    <br>
    <ul>
      <li>Programme:</li>
      <li><a href="#programme4">July 4<sup>th</sup></a></li>
      <li><a href="#programme5">July 5<sup>th</sup></a></li>
      <li><a href="#programme6">July 6<sup>th</sup></a></li>
      <li><a href="#programmeOnline">Online</a></li>
    </ul>
    <br>
    <ul>
      <li>Awards:</li>
      <li><a href="#bestPaper">Best Paper</a></li>
      <li><a href="#bestMusic">Best Music & Sonic Art</a></li>
    </ul>
    <br>
    <ul>
      <li>Proceedings:</li>
      <li><a href="https://zenodo.org/records/13918961">SMC2024 Book</a></li>
    </ul>
  	</nav>
    </section></div>
</header>
<main>

<section id="about" class="b"><div class="inner">
<h3 class="noMargin">Immersive <strong>Sound</strong></h3>
<h3 class="noMargin">Immersive <strong>Music</strong></h3>
<h3>Immersive <strong>Computing</strong></h3>
<p>The quest for <em>immersion</em> is — quite literally — all around us, and it has been a significant driver of research and development in the academy, the industry, and within artistic communities in the past decades. But what makes an experience <em>immersive</em>?</p>
<p>Spatial sound quickly comes to mind, and it will be a very relevant part of SMC 2024, both in the paper and the music / sonic art sessions. But there is more to <em>immersion</em> than spatial sound alone:</p>
<ul><li>the timbral possibilities afforded by novel sound design and synthesis algorithms certainly play a big role in the envelopment of a sonic experience <em>(immersive sound)</em>;</li>
<li>the temporal development of musical discourse and performance can determine its ability to become, as T. S. Eliot famously wrote, “Music heard so deeply / That is not heard at all, but you are / The music / While the music lasts" <em>(immersive music)</em>;</li>
<li>new strategies to engage with digital sound and music, both on studio and on stage, can open new paths for involving human computer interaction <em>(immersive computing)</em>.</li></ul>
<p>All of these themes — and much more — were addressed in <strong>SMC 2024</strong>: have a look at the Conference's <a href="https://flic.kr/s/aHBqjBygFU">flickr album</a>!</p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>


<section id="call_papers" class="c"><div class="inner">
<h3>Call for Papers</h3>
<p>As in previous years, SMC welcomes original, previously unpublished contributions between 4 and 8 pages, written in English, which must be submitted as PDF documents generated from <a href="https://smcnetwork.org/smc2024/SMC2024_templates.zip">the SMC paper template</a>. Authors of accepted papers will be required to prepare 2-minute video presentations of their work, to be made available on the conference website. Those attending in person will be presenting their work in poster and demo sessions preceded by a short kick-off oral session featuring a 5-minute presentation per poster or demo.</p>
<p>This year's theme is <em><strong>Immersive Sound, Immersive Music, Immersive Computing</strong></em>. Submissions emphasizing these topics are strongly encouraged. Other topics include, but are not limited to:</p>
<ul class="noPadding">
<li>Algorithms and Systems for music composition</li>
<li>Auditory display and data sonification</li>
<li>Automatic separation, recognition, classification of sound and music</li>
<li>Automatic music generation/accompaniment systems</li>
<li>Computational musicology and ethnomusicology</li>
<li>Content processing of music audio signals</li>
<li>Digital audio effects</li>
<li>Hardware systems for sound and music computing</li>
<li>Humanities in Sound and Music Computing</li>
<li>Interactive performance systems</li>
<li>Interfaces for sound and music</li>
<li>Languages, protocols, and software environments for sound and music computing</li>
<li>Models for sound analysis and synthesis</li>
<li>Multimodality in sound and music computing</li>
<li>Music creation and performance</li>
<li>Music information retrieval</li>
<li>Music performance analysis and rendering</li>
<li>Perception and cognition of sound and music</li>
<li>Social interaction in sound and music computing</li>
<li>Sonic interaction design</li>
<li>Sound and music for accessibility and special needs</li>
<li>Sound and music for Augmented/Virtual Reality and games</li>
<li>Sound/music and the neurosciences</li>
<li>Sound/music signal processing algorithms</li>
<li>Spatial sound, reverberation, and virtual acoustics</li>
<li>Technologies for the preservation, access and modelling of musical heritage</li>
</ul>
<p>All submissions will be peer-reviewed, but authors are not required to anonymize them: SMC 2024 applies a single-blind peer review. All accepted papers are to be included in the SMC 2024 Conference Proceedings, but please note that publication is conditional to conference tion of the presenting author. Kindly indicate in the submission form if the first author of a submission is a student author. tion instructions and fees will be published in January 2024. The Proceedings will have an ISBN and the electronic version will be available on the <a href="http://smcnetwork.org/">SMC website</a> and <a href="https://zenodo.org/communities/smc/">Zenodo</a>.</p>
<p>Submissions should be made using the <a href="https://cmt3.research.microsoft.com/SMC2024">SMC2024 Conference Management Toolkit's website</a>. The submission of the title, abstract, and complete list of authors should be done first, followed by the submission of the full paper as PDF (maximum file size: 20MB).</p>
<p><strong>Title & abstract submission deadline (strict!)</strong>: February 24<sup>th</sup>, 2024.</p>
<p><strong>Paper submission (strict!):</strong> March 11<sup>th</sup>, 2024</p>
<p>For any questions, please contact the SMC 2024 Scientific Chairs: <a href="mailto:guilherme.campos@ua.pt">Guilherme Campos</a>, <a href="mailto:insc@esmae.ipp.pt">Inês Salselas</a> and <a href="mailto:jnvieira@ua.pt">José Vieira</a>.</p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="call_music" class="d"><div class="inner">
<h3>Call for Music & Sonic Art</h3>
<p>SMC 2024 welcomes Music & Sonic Art contributions that are related to the core topics in Sound and Music Computing research for the concert program during the conference week. Concerts, performances and installations during SMC 2024 will be programmed in the most appropriate space at or around ESMAE and live performances are specially encouraged.</p>
<p>The theme of this year's SMC conference is <em><strong>Immersive Sound, Immersive Music, Immersive Computing</strong></em>. Submissions emphasizing these topics are strongly encouraged.</p>
<p>Music & Sonic Art from any genre and in any formats is invited for submission. All submissions will be peer-reviewed, but authors are not required to anonymize them: SMC 2024 applies a single-blind peer review. The review will happen in two rounds:</p>
<ul>
<li>The first is a single-blind peer review by the Artistic Committee, that will judge the quality and relevance of the proposal for the SMC conference.</li>
<li>On the second round, the Organising Committee will address the feasibility of the selected pieces and build the concert and installation programmes for the conference.</li>
</ul>
<p>It is thus very important that all submissions state very clearly the human and technical resources needed for each performance and installation, as well as which of those resources will be provided by the authors and which are expected to be provided by the host institution. ESMAE hosts state of the art audio equipment (including immersive sound systems), as well as musicians in various traditions and formations (from solo to symphonic orchestra).</p>
<p>Participants are encouraged to explore, but of course not limit to:</p>
<ul>
<li>Live solo or ensemble: solo or ensemble performances that can be performed live, with or without the use of immersive audio and/or video technologies. A recording of the edited ensemble has to be submitted for review, however the accepted works will be performed live on-site.</li>
<li>Media-based performances: pre-recorded music & sonic art performances leveraging immersive audio and/or video technologies.</li>
<li>Installations: music & sonic art installations, with or without the use of interactivity.</li>
</ul>
<p>Submissions should be made using the <a href="https://cmt3.research.microsoft.com/SMC2024">SMC2024 Conference Management Toolkit's website</a>. The submission of the title, abstract, and complete list of authors should be done first, followed by the submission of the proposal and supplementary files:</p>
<p>Mandatory files (two PDF files, maximum size 20MB each):</p>
<ul>
<li>A submission proposal with description of the performance / installation in the form of program notes.</li>
<li>A detailed technical rider, which should clearly specify how long the performance will last and include the details of both technical requirements and setup times.</li>
</ul>
<p>Supplementary files (up to five files, maximum size 500 MB each, using formats mp4, mov, wav, aif, flac, mp3, and pdf), which can be added using the option "Upload Supplementary Material", available in CTM's Author Console after the creation of the submission:</p>
<ul>
<li>Audio / Audiovisual performance / documentation of the piece.</li>
<li>The score of the work (if applicable).</li>
<li>Other relevant files.</li>
</ul>
<p><strong>Title & abstract submission deadline (strict!)</strong>: February 24<sup>th</sup>, 2024.</p>
<p><strong>Music & sonic art submission (strict!):</strong> March 11<sup>th</sup>, 2024</p>
<p>After notification of acceptance, all participants have a chance to further edit the uploaded material to make a performance-ready submission. Only one submission per participant will be accepted. Please note the submission proposal is for informative purposes for the selection and will not be included in the conference proceedings. Artists must hold the copyright of submitted materials to be used in SMC2024.</p>
<p>Each accepted music submission needs to be covered by an in-person registration (student or full, as appropriate). If the authors of the music submission are already SMC 2024 paper authors and have registered for the conference, their music submission can be covered with the same registration. Kindly indicate in the submission form if the first author of a submission is a student author.</p>
<p>For any questions, please contact the SMC 2024 Music Chairs: <a href="mailto:AMSDP@esmae.ipp.pt">Ângela da Ponte</a>, <a href="mailto:dimitrisandrikopoulos@esmae.ipp.pt">Dimitrios Andrikopoulos</a> and <a href="mailto:ruipenha@esmae.ipp.pt">Rui Penha</a>.</p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="submit" class="a"><div class="inner">
<h3>Important Dates</h3>
<ul class="checklist">
<li class="done"><strong>November 7<sup>th</sup>, 2023:</strong> SMC 2024 web site is launched.</li>
<li class="done"><strong>November 15<sup>th</sup>, 2023:</strong> Calls for papers / music & sonic art published.</li>
<li class="done"><strong>February 24<sup>th</sup>, 2024:</strong> Deadline for submitting an abstract and registering the paper music & sonic art on the conference portal <strong>(strict!)</strong>.</li>
<li class="done"><strong>March 11<sup>nd</sup>, 2024:</strong> Deadline for paper / music & sonic art submission <strong>(strict!)</strong>.</li>
<li class="done"><strong>April 21<sup>st</sup>, 2024:</strong> Deadline for submitting reviews.</li>
<li class="done"><strong>April 28<sup>th</sup>, 2024:</strong> Notification of acceptance.</li>
<li class="done"><strong>April 28<sup>th</sup>, 2024:</strong> Conference / Summer School registration open.</li>
<li class="done"><strong>June 5<sup>th</sup>, 2024:</strong> Camera-ready version due.</li>
<li class="done"><strong>June 5<sup>th</sup>, 2024:</strong> End of early-bird registration.</li>
</ul>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="registration" class="b"><div class="inner">
<h3>Registration</h3>
<p>Registration on SMC 2024 Conference and Summer School starts on April 7 and the early-bird registration period runs until June 5. Registration prices include the participation on all conference sessions, concerts, coffee-breaks, lunches and gala dinner. The SMC Summer School will be limited to 20 participants.</p>
<p>Early bird prices (until June 5):</p>
<ul class="noPadding">
<li>Full registration: <strong>€270</strong></li>
<li>Student registration: <strong>€150</strong></li>
<li>Summer School: <strong>€100</strong></li>
</ul>
<p>Normal prices (after June 5):</p>
<ul class="noPadding">
<li>Full registration: <strong>€320</strong></li>
<li>Student registration: <strong>€200</strong></li>
<li>Summer School: <strong>€150</strong></li>
</ul>
<p>Please fill the <a href="https://intranet.esmae.ipp.pt/candidaturas/index.php?evento=10">registration form here</a>.</p>
<p>For any questions regarding the conference, please contact <a href="mailto:smc2024@esmae.ipp.pt">smc2024@esmae.ipp.pt</a></p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="summer_school" class="c"><div class="inner">
<h3>Summer School</h3>
<p>1-3 July 2024 at the <a href="https://sigarra.up.pt/feup/en/WEB_PAGE.INICIAL">Faculty of Engineering, University of Porto</a> (FEUP).</p>
<p><strong>July 1st</strong></p>
<ul class="noPadding">
  <li>9:00 – reception</li>
  <li>9:30 – general introduction and information</li>
  <li>10:00 – Workshop with the <a href="https://soundparticles.com">Sound Particles</a> team</li>
  <li>13:00 – Lunch</li>
  <li>14:30 – Workshop with <a href="https://carlosguedes.org">Carlos Guedes</a></li>
  <li>17:30 – coffee break (fee)</li>
</ul>
<p><strong>July 2nd</strong></p>
<ul class="noPadding">
  <li>10:00 – Workshop with the <a href="https://soundparticles.com">Sound Particles</a> team hands on approach</li>
  <li>13:00 – Lunch</li>
  <li>14:30 – Workshop with <a href="https://franciscagoncalves.com">Francisca Rocha Gonçalves</a></li>
  <li>17:30 – coffee break (fee)</li>
</ul>
<p><strong>July 3rd</strong></p>
<ul class="noPadding">
  <li>10:00 – Project Lab</li>
  <li>13:00 – lunch</li>
  <li>14:30 – Project Lab & rehearsals at THSC</li>
  <li>19:00 – Sound and Music Computing Summer School 2024 Final Concert</li>
</ul>
<p><strong>Workshop with Sound Particles</strong></p>
<p>“Sound Particles is an immersive audio software capable of generating thousands (even millions) of sounds in a virtual 3D audio world. Creating highly complex sounds has never been this quick.”</p>
<p>In this workshop, participants will discover the amazing software developed by Sound Particles and used by great artists and music producers in the Hollywood industry. Its flexibility enables users to work in different audio formats for different media (film, VR, TV or videogames).</p>
<p><strong>Workshop with Carlos Guedes</strong> <em>Immersion, music, technology and ethics: four important variables of a complex equation</em></p>
<p>Immersion — the process by which one or more of the senses become saturated as environmental objects surround us — is an important concept in understanding culture and technology in the 21st century. Its pervasiveness is so widespread that in many situations it is hard to understand the degree of immersion one is at in our everyday lives. Although the idea of immersion in arts rather ancient, technological developments in the past 40 years or so led to a disengagement of the immersive experience from the place where it occurs making it increasingly present in our lives. The way we engage with music listening is perhaps at the forefront of this radical development in contemporary life, with the appearance of the Walkman. The idea of carrying one’s music everywhere led the way to carrying our own realities everywhere with the advent of mobile technologies that not only play our music, but also our own worlds (photos, videos) and constantly mediate our connection with the outside world.</p>
<p>Music making has often led to socio-cultural revolutions in ways that were at times disruptive leading to profound societal changes (cf. Jacques Attali’s <em>Noise</em>). Looking into what is going on with music creation these days, through the availability of cheap recording technologies, the impact of generative artificial intelligence, social media and the widespread availability of streaming services, important issues are raised.  The apparent ease with which one is able to record, create, and make available music digitally is paradoxically excluding some music cultures systematically. The technologies we are developing (including AI) are systematically biased by cultural beliefs and assumptions, raising deep ethical questions about the supposedly inclusive nature of these ubiquitous technologies.</p>
<p>This workshop focuses on the problems raised by the current state of affairs and aims to raise critical awareness on the issues highlighted above. It is oriented to musicians and technology developers without any assumption of specialized technical background. By looking at some philosophical concepts, media studies, and some state-of-the-art work currently being undertaken, it is aimed at being a provocatory/idea generation session on how to tackle these issues towards a more inclusive technological development.</p>
<p><strong>Workshop with Francisca Rocha Gonçalves</strong></p>
<p>In this workshop, participants will explore the depths of aquatic environments and discover the hidden soundscapes of aquatic life. Using specialised equipment such as hydrophones, they will embark on a journey to listen, record and connect with the underwater world.</p>
<p>The aim is to introduce participants to underwater soundscapes, their ecological significance, and the techniques for recording and understanding them. To reconnect participants and natural environments while raising awareness of the problem of underwater noise pollution.</p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="keynote_speakers" class="d"><div class="inner">
<h3>Keynote Speakers</h3>
<p id="keynote1"><strong>Keynote 1</strong> July 4<sup>th</sup>, 14h30</p>

<p><strong><em>Enactive Immersion</em>, by Dermot Furlong</strong></p>
<p>Recorded Music is now the most popular form of Music Listening.</p>
<p>Stereo recording has become the accepted commercial norm for audio recording and production. Coincident and Spaced stereo recording techniques were adopted as two standards for stereo recording, each allowing for particular Listener perceptual phenomena to be emphasized.</p>
<p>Coincident stereo capabilities were technologically developed to specify a pan-pot stereo Localisation experience, thereby enabling creative studio recorded music production. Coincident stereo was therefore accepted as an artistically viable studio recorded music production technique.</p>
<p>Spaced stereo recording presents listeners with a degree of Immersion experience, which is often an aesthetically appealing feature of the reconstructed sound. However, to date a creative Immersion control capability has not been realised for studio production use.</p>
<p>This is an artistic limitation, which contributed to the definition and development of a variety of alternative ‘Surround Sound’ formats over the decades for spatial experience extension.</p>
<p>The question of how 2-channel stereo recordings could be technologically processed to facilitate the artistic manipulation of Listener Immersive experience is offered new answers by the adoption of the Enaction worldview. Enaction demands a focus on the required sensory signal characteristics which enable auditory Immersion to be experienced. These enabling signal characteristics permit the operation of the mental Image Schemas (Organizing Ideas) that are relevant for the perception of Immersion.</p>
<p>Enactive processing thereby permits effective control of varying degrees of perceptual Immersion based on manipulation of standard 2 channel stereo format signals.</p>
<p><a class="btn" href="https://www.youtube.com/watch?v=g8Ef8VTRB1s">video recording</a></p>
<div class="keynote-container">
  <div class="keynote-photo">
    <img class="keynote" src="imagens/Furlong.jpg" alt="Furlong">
  </div>
  <div class="keynote-text">
    <p><strong><a href="https://www.tcd.ie/eleceng/mmt/news/Dermot-Furlong/">Dermot Furlong</a></strong> studied Engineering Science in Trinity College Dublin with a particular personal focus on electronics, acoustics, and audio engineering. He also studied classical guitar and developed an interest in musical acoustics and recording techniques. He subsequently worked as a corporate engineer for Westinghouse Electric in the U.S. and Ireland before returning to Trinity as a lecturer so that he could engage in further research on audio and music related issues. His area of particular interest is that of architectural acoustics, spatial audio perception and its significance for music recording technique. In 1995 he was involved in the definition of the postgraduate Music and Media Technologies (MMT) programme in Trinity, for which he has been Course Director since its initiation in 1996. His current research interests relate to the development of audio engineering technologies derived from musical and cognitive concerns. He has been a member of the Audio Engineering Society, the Acoustical Society of America, and EUCognition.</p>
    
  </div>
</div>
<p id="keynote2"><strong>Keynote 2</strong> July 5<sup>th</sup>, 14h30</p>
<p><strong><em>Underwater Soundscapes: fostering connection and awareness through sonic immersion</em>, by Francisca Rocha Gonçalves</strong></p>
<p>In this keynote, I will explore the concept of immersion applied to my personal artistic practice, specifically through the medium of underwater sound recordings. My work connects with a growing awareness into the experience of being fully present in the moment—both during the process of capturing the subtle, often unnoticed sounds of the underwater world, and in the deep, attentive listening that follows.</p>
<p>Sound, as an artistic and sensory medium, has the unique ability to induce a state of intense focus, allowing us to transcend our immediate surroundings and connect with the environment on a more intimate level. The idea is to examine how such immersive practices can foster a heightened awareness and appreciation for the sonic world around us, nurturing a deeper connection with our environment, while promoting nature-connectedness.</p>
<p>By integrating this hyperfocus into our daily lives, we can elevate our presence and mindfulness, using our acute attention to sound as a means to deepen our environmental appreciation. I will draw from my artistic practice to share insights, including examples of how underwater soundscapes have been essential in creating this personal immersive experience. We will examine the impact of attentive listening, and the broader implications for using this “superpower” of deep tuning to enrich our daily lives and strengthen our connection to the natural world.</p>
<p>Exploring the intersection of art, sound, and attention, the objective is to discover how the practice of immersive listening can eventually transform our perception of the world and our place within it.</p>
<p><a class="btn" href="https://www.youtube.com/watch?v=LttY4Dwsh6U">video recording</a></p>
<div class="keynote-container">
  <div class="keynote-photo">
    <img class="keynote" src="imagens/Goncalves.jpg" alt="Goncalves">
  </div>
  <div class="keynote-text">
    <p><strong><a href="https://franciscagoncalves.com">Francisca Rocha Gonçalves</a></strong> is a researcher from Porto, currently living in Berlin. Recently worked on the AQUATAG project at the IGB Leibniz Institute of Freshwater Ecology and Inland Fisheries. Has a background in biological sciences with a degree in Veterinary Medicine from ICBAS (University of Porto), a Multimedia Master in Interactive Music and Sound Design from FEUP (University of Porto), and a PhD in Digital Media from FEUP (University of Porto). The research focuses on acoustic ecology in artistic creation as a tool for environmental awareness concerning underwater soundscapes. Developing artistic artefacts that reveal the problem of noise pollution in underwater environments is possible to understand changes in vibration and particle motion, both vital components in aquatic life.<br>Combining interests in sound, technology, art and science, it aims to raise societal and environmental awareness through artistic practices and sound art. A great passion for biology and music led to a demand to find synergies between nature and sound. Bridging these two worlds, Francisca attempts to find new musical approaches, not only for musical compositions but also for live performances.<br>Presently is working for ICARUS, collaborating with Dr Johannes Goessling. ICARUS is an arts-science project that focuses on the photonic properties of diatoms and creates upscaled ice sculptures of their internal shells. Co-founder of the artistic collective Openfield Creative Lab. Co-founder of Ocean Soundscape Awareness project ØSAW.</p>
  </div>
</div>
<p id="keynote3"><strong>Keynote 3</strong> July 6<sup>th</sup>, 14h30</p>
<p><strong><em>Sound from everywhere: Immersive Realities and Fictions in Sound-art and Composition</em>, by Natasha Barrett</strong></p>
<p>When I was invited to present a keynote at SMC2024, I was inspired by the conference's central question: what makes an experience truly immersive? This concept can be interpreted in various ways, influenced by the listener, the context, and the technology available. Even the definition of 'immersive' is open to interpretation.</p>
<p>I decided to shape my presentation around these considerations, focusing on three immersive themes in my work with Ambisonics to create and control 3D soundfields in artistic interventions. These themes include site-specific outdoor immersive experiences in urban noise habitats, composed concert works, and live improvised immersive performances. A common theme across all these threads is the transformative role of the latest tools in realising our creative ideas. This progression results in an accumulation of knowledge and creativity in my artistic practice, rather than merely replacing the old with the new. At the end of the presentation I will play a real-time demo, an extract from an outdoor immersive sound installation, and insights into my current work in progress "Toxic Colour”.</p>
<p><a class="btn" href="https://www.youtube.com/watch?v=AxDzak_oe74">video recording</a></p>
<div class="keynote-container">
  <div class="keynote-photo">
    <img class="keynote" src="imagens/Barrett.jpg" alt="Barrett">
  </div>
  <div class="keynote-text">
    <p><strong><a href="https://www.natashabarrett.org">Natasha Barrett</a></strong> (NO/ UK) composes concert works, public space sound-art installations and multimedia interactive music using a broad palette of sounds, new technologies and experimental techniques. She is widely known for her electroacoustic and acousmatic music, and use of 3D sound technology in composition. Her work is commissioned and performed throughout the world and has received over 20 international awards including the Nordic Council Music Prize, the Giga-Hertz Award (Germany), five prizes and the Euphonie D'Or in the Bourges International Electroacoustic Music Awards (France), two first prizes in the International Rostrum for electroacoustic music and most recently the honorary Thomas Seelig Fixed Media Award for 2023. She regularly collaborates with performers, visual artists, architects and scientists, is active as a performer of live-electronics and spatial audio, as a researcher has a track record in both artistic and academic publications and has held professorships at institutions in Norway and Denmark.</p>
  </div>
</div>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="programme4" class="a"><div class="inner">
<h3>Programme</h3>
<p></p>
<div class="schedule_container">
  <table>
    <thead>
      <tr>
        <th class="none">July 4<sup>th</sup></th>
        <th class="none">Session</th>
        <th class="none">Place</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="hour">09h00</td>
        <td>Reception</td>
        <td>Entrance</td>
      </tr>
      <tr>
        <td class="hour">10h30</td>
        <td>Opening</td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">11h00</td>
        <td><a href="#paper1">Paper kick-off 1</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">12h00</td>
        <td><a href="#paper1">Poster/Demo 1</a></td>
        <td>Room 213</td>
      </tr>
      <tr>
        <td class="hour">13h00</td>
        <td><em>lunch</em></td>
        <td>Blackbox</td>
      </tr>
      <tr>
        <td class="hour">14h30</td>
        <td><a href="#keynote1">Keynote 1</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">15h30</td>
        <td><a href="#paper2">Paper kick-off 2</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">16h30</td>
        <td><a href="#paper2">Poster/Demo 2</a></td>
        <td><em>coffee-break</em></td>
      </tr>
      <tr>
        <td class="hour">17h30</td>
        <td><a href="#paper3">Paper kick-off 3</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">18h30</td>
        <td><a href="#paper3">Poster/Demo 3</a></td>
        <td>Room 213</td>
      </tr>
      <tr>
        <td class="hour">19h30</td>
        <td><a href="#concert1">Concert 1</a></td>
        <td>Theatre</td>
      </tr>
    </tbody>
  </table>
</div>
<p id="paper1"><strong>Paper & Poster/Demo session 1</strong> July 4<sup>th</sup>, 11h00</p>
<ul>
  <li><em>Guiding Co-Creative Musical Agents through Real-Time Flute Instrumental Playing Technique Recognition</em><br><strong>Marco Fiorini</strong> (IRCAM, Sorbonne Université, CNRS)<br><strong>Nicolas Brochec</strong> (Tokyo University of the Arts)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14334950">paper</a><a class="btn" href="videos/SMC2024_video_id58.mp4">video</a></li>
  <li><em>A Geographically Distributed Performance Mediated by a Co-Creative Agent over the Web</em><br><strong>Thales Roel P. Pessanha</strong> (University of Coimbra, CISUC, DEI)<br><strong>Pedro Martins</strong> (University of Coimbra, CISUC, DEI)<br><strong>Jônatas Manzolli</strong> (University of Campinas, NICS)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335001">paper</a><a class="btn" href="videos/SMC2024_video_id119.mp4">video</a></li>
  <li><em>Performing Voices in Immersive Theater: Kinesthesis 2.0 for Embodied Performance.</em><br><strong>Tilemachos Moussas</strong> (University Of Athens)<br><strong>Anastasia Georgaki</strong> (NKUA)<br><strong>Natalia Kotsani</strong> (National Technical University of Athens)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335121">paper</a><a class="btn" href="videos/SMC2024_video_id148.mp4">video</a></li>
  <li><em>Real-time Piano Accompaniment Model Trained on and Evaluated According to Human Ensemble Characteristics</em><br><strong>Kit C Armstrong</strong> (National Tsing Hua University)<br><strong>Tzu-Ching Hung</strong> (National Tsing Hua University)<br><strong>Ji-Xuan Huang</strong> (National Tsing Hua University)<br><strong>Yi-WenLiu</strong> (National Tsing Hua University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335624">paper</a><a class="btn" href="videos/SMC2024_video_id179.mp4">video</a></li>
  <li><em>Real-time Future-rhythm Visualizer for DJ Performance</em><br><strong>Masatoshi Hamanaka</strong> (RIKEN)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335732">paper</a><a class="btn" href="videos/SMC2024_video_id66.mp4">video</a></li>
  <li><em>SMUG-Explain: A Framework for Symbolic Music Graph Explanations</em><br><strong>Emmanouil Karystinaios</strong> (Johannes Kepler University)<br><strong>Francesco Foscarin</strong> (Johannes Kepler University Linz)<br><strong>Gerhard Widmer</strong> (Johannes Kepler University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335792">paper</a><a class="btn" href="videos/SMC2024_video_id95.mp4">video</a></li>
  <li><em>Patterns UI, an Interactive Tool for Music Exploration</em><br><strong>Rory Sweeney</strong> (University of Galway)<br><strong>Pushkar Jajoria</strong> (University of Ireland)<br><strong>Danny Diamond</strong> (University of Galway)<br><strong>Mathieu D'Aquin</strong> (Université de Lorraine)<br><strong>James McDermott</strong> (University of Galway)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14335898">paper</a><a class="btn" href="videos/SMC2024_video_id99.mp4">video</a></li>
</ul>
<p id="paper2"><strong>Paper & Poster/Demo session 2</strong> July 4<sup>th</sup>, 15h30</p>
<ul>
  <li><em>Exploring Sampling Strategies in Latent Spaces for Music Generation</em><br><strong>Nádia Carvalho</strong> (University of Porto, Faculty of Engineering & INESC TEC)<br><strong>Gilberto Bernardes</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336029">paper</a><a class="btn" href="videos/SMC2024_video_id92.mp4">video</a></li>
  <li><em>Guitar Chord Diagram Suggestion for Western Popular Music</em><br><strong>Alexandre D'Hooge</strong> (Université de Lille)<br><strong>Louis Bigo</strong> (Université de Lille)<br><strong>Ken Déguernel</strong> (CNRS)<br><strong>Nicolas Martin</strong> (Arobas Music)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336096">paper</a><a class="btn" href="videos/SMC2024_video_id142.mp4">video</a></li>
  <li><em>A Sonification Method for Monitoring Chemical Sensor Data</em><br><strong>Yutian Hu</strong> (Queen Mary University of London)<br><strong>Tony Stockman</strong> (Queen Mary University of London)<br><strong>Aleksandar Radu</strong> (University of Lincoln)<br><strong>Ernesto Saiz</strong> (Teesside University)<br><strong>Nick Bryan-Kinns</strong> (University of the Arts London)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336163">paper</a><a class="btn" href="videos/SMC2024_video_id173.mp4">video</a></li>
  <li><em>Interactive Musical Periodic Table: Sonification of Visible Element Emission Spectra</em><br><strong>William W Smith</strong> (Royal Conservatory The Hague)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336263">paper</a><a class="btn" href="videos/SMC2024_video_id192.mp4">video</a></li>
  <li><em>Interpretative Data Sonification: Using LLMs to Interpret Data and Generate Continuous Soundscapes at the Sydney Opera House</em><br><strong>Rodolfo Ocampo</strong> (UNSW)<br><strong>Oliver R Bown</strong> (University of New South Wales)<br><strong>JustinShave </strong> (Uncanny Valley Music)<br><strong>BrendanWright</strong> (Uncanny Valley Music )<br><strong>Caroline Pegram</strong> (Uncanny Valley)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336322">paper</a><a class="btn" href="videos/SMC2024_video_id243.mp4">video</a></li>
  <li><em>Arpeggiatorum: an Audio Controllable MIDI Arpeggiator</em><br><strong>Davide Andrea Mauro</strong> (Paderborn University)<br><strong>Axel Berndt</strong> (Paderborn University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336426">paper</a><a class="btn" href="videos/SMC2024_video_id57.mp4">video</a></li>
  <li><em>Soundscape Personalisation at Work: Designing AI-Enabled Sound Technologies for the Workplace</em><br><strong>Thomas Deacon</strong> (University of Surrey)<br><strong>Arshdeep Singh</strong> (University of Surrey)<br><strong>Gabriel Bibbó</strong> (University of Surrey)<br><strong>Mark D. Plumbley</strong> (University of Surrey)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336495">paper</a><a class="btn" href="videos/SMC2024_video_id117.mp4">video</a></li>
  <li><em>A Generative Framework for Composition-aware Loop Recommendation In Music Production: Drum2Bass Use Case</em><br><strong>Xiaowan Yi</strong> (Centre for Digital Music, Queen Mary Univeristy of London)<br><strong>Mathieu Barthet</strong> (Queen Mary University of London)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336568">paper</a><a class="btn" href="videos/SMC2024_video_id140.mp4">video</a></li>
</ul>
<p id="paper3"><strong>Paper & Poster/Demo session 3</strong> July 4<sup>th</sup>, 17h30</p>
<ul>
  <li><em>Vibrotactile Memory: a Case Study of Timbre Perception Training in Children with Cochlear Implants Using a Video Game</em><br><strong>Francesco Ganis</strong> (Aalborg University)<br><strong>Ali Adjorlu</strong> (Aalborg University Copenhagen)<br><strong>Lone Marianne Percy-Smith</strong> (Rigshospitalet Copenhagen University Hosptial)<br><strong>Cecilia Fernandez Samar</strong> (Rigshospitalet Copenhagen University Hosptial)<br><strong>Stefania Serafin</strong> (Aalborg)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336923">paper</a><a class="btn" href="videos/SMC2024_video_id109.mp4">video</a></li>
  <li><em>Assessing Musical Preferences of Children on the Autistic Spectrum: Implications for Therapy</em><br><strong>Natália Isabel Santos</strong> (University of Porto, Faculty of Engineering & INESC TEC)<br><strong>Gilberto Bernardes</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><strong>Rita Alcântara</strong> (University Center of the State of Pará-CESUP)<br><strong>Nilzabeth Coelho</strong> (University Center of the State of Pará-CESUP)<br><strong>Alessandra Baganha</strong> (University Center of the State of Pará-CESUP)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14336976">paper</a><a class="btn" href="videos/SMC2024_video_id133.mp4">video</a></li>
  <li><em>An Accessible Software Interface for Collaborative Music Performance</em><br><strong>Vanessa Faschi</strong> (Università degli Studi di Milano)<br><strong>Luca Andrea Ludovico</strong> (University of Milan)<br><strong>Federico Avanzini</strong> (Università degli Studi di Milano)<br><strong>Emanuele Parravicini</strong> (Audio Modeling)<br><strong>Manuele Maestri</strong> (Musica Senza Confini)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337032">paper</a></li>
  <li><em>Singing for Anxiety: Exploring the Potentials of Singing in Immersive Virtual Reality to Help Children with Social Anxiety</em><br><strong>Ali Adjorlu</strong> (Aalborg University Copenhagen)<br><strong>Stefania Serafin</strong> (Aalborg)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337091">paper</a></li>
  <li><em>From MIDI to Rich Tablatures: an Automatic Generative System Incorporating Lead Guitarists' Fingering and Stylistic Choices</em><br><strong>Pierluigi Bontempi</strong> (University of Padua)<br><strong>Daniele Manerba</strong> (University of Brescia)<br><strong>Alexandre D'Hooge</strong> (Université de Lille)<br><strong>Sergio Canazza</strong> (University of Padua)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337138">paper</a><a class="btn" href="videos/SMC2024_video_id54.mp4">video</a></li>
  <li><em>I Got Rhythm, so Follow Me More: Modeling Score-dependent Timing Synchronization in a Piano Duet</em><br><strong>Akira Maezawa</strong> (Yamaha Corporation)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337192">paper</a><a class="btn" href="videos/SMC2024_video_id136.mp4">video</a></li>
  <li id="bestPaper"><em>Simulating Piano Performance Mistakes for Music Learning</em><br><strong>Alia Morsi</strong> (Universitat Pompeu Fabra)<br><strong>Huan Zhang</strong> (Queen Mary University of London)<br><strong>Akira Maezawa</strong> (Yamaha Corporation)<br><strong>Simon Dixon</strong> (Queen Mary University of London)<br><strong>Xavier Serra</strong> (Universitat Pompeu Fabra)<br><strong><font color="#FCFBAB">[ Awarded Best Paper of SMC 2024 ]</font></strong><br><a class="btn" href="https://doi.org/10.5281/zenodo.14337238">paper</a><a class="btn" href="videos/SMC2024_video_id171.mp4">video</a></li>
  <li><em>Tablature Generation from Lead Sheets for Finger-style Solo Guitar</em><br><strong>Shunsuke Sakai</strong> (Nihon University)<br><strong>Hinata Segawa</strong> (Nihon University)<br><strong>Tetsuro Kitahara</strong> (Nihon University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337320">paper</a><a class="btn" href="videos/SMC2024_video_id55.mp4">video</a></li>
  <li><em>Exploring Uncharted Soundscapes: Innovative Interaction and Mapping Techniques with the Bodyharp and the Teinophon</em><br><strong>Leo Fogadić</strong> (Aalborg University)<br><strong>Doga Cavdir</strong> (Aalborg University in Copenhagen)<br><strong>Dan Overholt</strong> (Aalborg University Copenhagen)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337378">paper</a><a class="btn" href="videos/SMC2024_video_id190.mp4">video</a></li>
</ul>
<p id="concert1"><strong>Concert 1</strong> July 4<sup>th</sup>, 19h30</p>
<ul>
  <li><em>Terminal</em><br><strong>Leonie Strecker</strong> (University of Music and Performing Arts Graz)<br><a class="btn" href="music/SMC2024_music&sonicArt_id43.pdf">program notes</a></li>
  <li><em>Travelling without moving</em><br><strong>Stefano Catena</strong> (De Montfort University)<br><a class="btn" href="music/SMC2024_music&sonicArt_id156.pdf">program notes</a></li>
  <li><em>Too waste, too fast </em><br><strong>Francesco Perissi</strong><br><a class="btn" href="music/SMC2024_music&sonicArt_id228.pdf">program notes</a></li>
  <li><em>Matters 8</em><br><strong>Daniel Mayer</strong> (Institute of Electronic Music and Acoustics / University of Music and Performing Arts Graz)<br><a class="btn" href="music/SMC2024_music&sonicArt_id257.pdf">program notes</a></li>
</ul>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>
<section id="programme5" class="b"><div class="inner">
<div class="schedule_container">
  <table>
    <thead>
      <tr>
        <th class="none">July 5<sup>th</sup></th>
        <th class="none">Session</th>
        <th class="none">Place</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="hour">09h00</td>
        <td>Reception</td>
        <td>Entrance</td>
      </tr>
      <tr>
        <td class="hour">10h00</td>
        <td><a href="#paper4">Paper kick-off 4</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">11h00</td>
        <td><a href="#paper4">Poster/Demo 4</a></td>
        <td><em>coffee-break</em></td>
      </tr>
      <tr>
        <td class="hour">12h00</td>
        <td><a href="#concert2">Concert 2</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">13h00</td>
        <td><em>lunch</em></td>
        <td>Blackbox</td>
      </tr>
      <tr>
        <td class="hour">14h30</td>
        <td><a href="#keynote2">Keynote 2</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">15h30</td>
        <td><a href="#paper5">Paper kick-off 5</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">16h30</td>
        <td><a href="#paper5">Poster/Demo 5</a></td>
        <td><em>coffee-break</em></td>
      </tr>
      <tr>
        <td class="hour">16h30</td>
        <td><a href="#installation">Installation</a></td>
        <td>Pavilhão 3</td>
      </tr>
      <tr>
        <td class="hour">17h30</td>
        <td>Industry Session</td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">20h30</td>
        <td><a href="#dinner">Conference Dinner</a></td>
        <td>Restaurant</td>
      </tr>
    </tbody>
  </table>
</div>
<p id="paper4"><strong>Paper & Poster/Demo session 4</strong> July 5<sup>th</sup>, 10h00</p>
<ul>
  <li><em>Quantifying Pitch Drift in Unaccompanied Solo Singing: A Computational Examination through Density-Based Clustering</em><br><strong>Sepideh Shafiei</strong> (Cu Test Inc)<br><strong>Shapour Hakam</strong> (Cu Test Inc)<br><strong>Arvin Nick</strong> (Cu Test Inc)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337696">paper</a><a class="btn" href="videos/SMC2024_video_id6.mp4">video</a></li>
  <li><em>Comparing Audio Boundary Annotation of Vocal Polyphony: Experts, Non-experts, and Algorithms</em><br><strong>Mirjam E. Visscher</strong> (Utrecht University)<br><strong>Frans Wiering</strong> (Utrecht University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337734">paper</a><a class="btn" href="videos/SMC2024_video_id36.mp4">video</a></li>
  <!-- <li><em>Algorithmic Analysis and Harmonic Database Generation for Musicologist</em><br><strong>Anaïs BINET</strong> (Université de Bordeaux / LaBRI)<br><strong>Myriam DESAINTE-CATHERINE</strong> (Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400, Talence, France)<br><a class="btn" href="papers/SMC2024_paper_id129.pdf">paper</a><a class="btn" href="videos/SMC2024_video_id129.mp4">video</a></li> -->
  <li><em>Exploring Perde-Space: 3-D Tonnetz Visualization for Makam Music</em><br><strong>Recep Gül</strong> (Istanbul Technical University)<br><strong>Ozan Baysal</strong> (Istanbul Technical University)<br><strong>Yavuz Buruk</strong> (Istanbul Technical University)<br><strong>Yusuf Can Şeftali</strong> (Istanbul Technical University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337758">paper</a><a class="btn" href="videos/SMC2024_video_id213.mp4">video</a></li>
  <li><em>Exploring Immersion and Spatial Audio Perception in Concerts for Hearing-Impaired and Normal Hearing Audiences</em><br><strong>Jesper Andersen</strong> (The Royal Danish Academy of Music)<br><strong>Stefania Serafin</strong> (Aalborg)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337849">paper</a><a class="btn" href="videos/SMC2024_video_id75.mp4">video</a></li>
  <li><em>The Elusive Nature of Inattentional Deafness: Assessing the Influence of Visual Attention on Background Music Perception in TV Programmes</em><br><strong>Roser Batlle-Roca</strong> (Universitat Pompeu Fabra)<br><strong>Diana Tyman</strong> (Universitat Pompeu Fabra)<br><strong>Blai Meléndez-Catalán</strong> (BMAT Licensing S.L.)<br><strong>Emilio Molina</strong> (BMAT)<br><strong>Xavier Serra</strong> (Universitat Pompeu Fabra)<br><strong>Perfecto Herrera-Boyer</strong> (Universitat Pompeu Fabra)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337895">paper</a><a class="btn" href="videos/SMC2024_video_id87.mp4">video</a></li>
  <li><em>Statistical Analysis of Musical Features for Emotional Semantic Differentiation in Human and AI Databases</em><br><strong>Francisco Braga</strong> (NOVA School of Science and Technology)<br><strong>Jorge F Forero</strong> (Ludique)<br><strong>Gilberto Bernardes</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14337968">paper</a><a class="btn" href="videos/SMC2024_video_id93.mp4">video</a></li>
  <li><em>Temporal Analysis of Emotion Perception in Film Music: Insights from the FME-24 Dataset</em><br><strong>Ruby O.N Crocker</strong> (Queen Mary University of London)<br><strong>George Fazekas</strong> (QMUL)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338011">paper</a><a class="btn" href="videos/SMC2024_video_id111.mp4">video</a></li>
  <li><em>BiSAID: Bipolar Semantic Adjectives Icons and Earcons Dataset</em><br><strong>Zijing Cao</strong> (University of Porto)<br><strong>Gilberto Bernardes</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><strong>António Sá Pinto</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338053">paper</a><a class="btn" href="videos/SMC2024_video_id184.mp4">video</a></li>
  <li><em>"Back in my day...": a Preliminary Study on the Differences in Generational Groups Perception of Musically-evoked Emotion</em><br><strong>Pedro L. Louro</strong> (DEI FCTUC, University of Coimbra)<br><strong>Renato Panda</strong> (Ci2.ipt, CISUC)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338088">paper</a><a class="btn" href="videos/SMC2024_video_id200.mp4">video</a></li>
  <li><em>Exploring the Emergence of Beat Induction Using a 'Swarm of Onsets' Generative Model</em><br><strong>Nolan Lem</strong> (Stanford University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338139">paper</a><a class="btn" href="videos/SMC2024_video_id220.mp4">video</a></li>
</ul>
<p id="concert2"><strong>Concert 2</strong> July 5<sup>th</sup>, 12h00</p>
<ul>
  <li><em>wood, metal and tension for violin and electronics</em><br><strong>Cárthach Ó Nuanáin</strong> (Cork School of Music)<br><a class="btn" href="music/SMC2024_music&sonicArt_id32.pdf">program notes</a></li>
  <li><em>Cryoconite</em><br><strong>Enrico Dorigatti</strong> (University of Portsmouth)<br><a class="btn" href="music/SMC2024_music&sonicArt_id47.pdf">program notes</a></li>
  <li><em>mirrored: ceilings, floors, walls</em><br><strong>youngjae cho</strong><br><a class="btn" href="music/SMC2024_music&sonicArt_id248.pdf">program notes</a></li>
  <li id="bestMusic"><em>TransVariations – Music beyond the limits of time and technology</em><br><strong>Oeyvind Brandtsegg</strong> (Norwegian University of Science and Technology)<br><strong>Alfonso Benetti</strong> (University of Aveiro)<br><strong>Trond Engum</strong> (Norwegian University of Science and Technology)<br><strong>Francisco Monteiro</strong> (Instituto Politécnico do Porto)<br><strong><font color="#FCFBAB">[ Awarded Best Music & Sonic Art of SMC 2024 ]</font></strong><br><a class="btn" href="music/SMC2024_music&sonicArt_id256.pdf">program notes</a></li>
</ul>
<p id="paper5"><strong>Paper & Poster/Demo session 5</strong> July 5<sup>th</sup>, 15h30</p>
<ul>
  <li><em>Beamix: Application of an Ambisonics Filter Bank for the Creation of Directional Effects</em><br><strong>Thibaut Carpentier</strong> (Ircam)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338799">paper</a><a class="btn" href="videos/SMC2024_video_id97.mp4">video</a></li>
  <li><em>Toward a Novel Set of Pinna Anthropometric Features for Individualizing Head-Related Transfer Functions</em><br><strong>Davide Fantini</strong> (Università degli Studi di Milano)<br><strong>Stavros Ntalampiras</strong> (University of Milan)<br><strong>Giorgio Presti</strong> (Università degli Studi di Milano)<br><strong>Federico Avanzini</strong> (Università degli Studi di Milano)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14338959">paper</a><a class="btn" href="videos/SMC2024_video_id141.mp4">video</a></li>
  <li><em>A Speaker Agnostic Approach to Spatialisation in Electroacoustic Music</em><br><strong>Stefano Catena</strong> (De Montfort University)<br><strong>Henrik Frisk</strong> (Royal College of Music Stockholm)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339003">paper</a><a class="btn" href="videos/SMC2024_video_id145.mp4">video</a></li>
  <li><em>Csound vs. ChucK: Sound Generation for XR Multi-Agent Audio Systems in the Meta Quest 3 Using the Unity Game Engine</em><br><strong>Pedro P Lucas</strong> (University of Oslo)<br><strong>Stefano Fasciani</strong> (University of Oslo)<br><strong>Kyrre Glette</strong> (Oslo University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339047">paper</a><a class="btn" href="videos/SMC2024_video_id202.mp4">video</a></li>
  <li><em>Comparing Four 360-Degree Cameras for Spatial Video Recording and Analysis</em><br><strong>Jinyue Guo</strong> (University of Oslo)<br><strong>Maham Riaz</strong> (University of Oslo)<br><strong>Alexander Refsum Jensenius</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339096">paper</a><a class="btn" href="videos/SMC2024_video_id122.mp4">video</a></li>
  <li><em>Exploring Convolutional Neural Networks for Multimodal Classification of Expressive Piano Performance</em><br><strong>Anna-Maria Christodoulou</strong> (University of Oslo)<br><strong>Sagar Dutta</strong> (University of Oslo)<br><strong>Olivier Lartillot</strong> (University of Oslo)<br><strong>Kyrre Glette</strong> (Oslo University)<br><strong>Alexander Refsum Jensenius</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339149">paper</a><a class="btn" href="videos/SMC2024_video_id151.mp4">video</a></li>
  <li><em>Combining Hand Pose Estimation with Audio for Noise-robust Piano Score Following</em><br><strong>Kaitlin Pet</strong> (Indiana University )<br><strong>Akira Maezawa</strong> (Yamaha Corporation)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339207">paper</a><a class="btn" href="videos/SMC2024_video_id155.mp4">video</a></li>
  <li><em>IEMI: an Immersive, Evolving Motion-controlled Installation</em><br><strong>Ahmet Emin Memis</strong> (University of Oslo)<br><strong>Tejaswinee Kelkar</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339258">paper</a><a class="btn" href="videos/SMC2024_video_id158.mp4">video</a></li>
  <li><em>A Cover Image Composition Method for Music Content Using Multimodal Image Retrieval and Cropping Techniques</em><br><strong>Takayuki Nakatsuka</strong> (National Institute of Advanced Industrial Science and Technology (AIST))<br><strong>Masahiro Hamasaki</strong> (National Institute of Advanced Industrial Science and Technology (AIST))<br><strong>Masataka Goto</strong> (National Institute of Advanced Industrial Science and Technology (AIST))<br><a class="btn" href="https://doi.org/10.5281/zenodo.14339315">paper</a><a class="btn" href="videos/SMC2024_video_id244.mp4">video</a></li>
</ul>
<p id="installation"><strong>Installation</strong></p>
<ul>
  <li>July 5<sup>th</sup>, 16h30 onwards<br><em>Transimmanency Symbiotic Treatments, Trans-interactive installation with web and bright resonant objects</em><br><strong>Lorenzo Ballerini</strong> (Conservatory of Trapani)<br><strong>Alberto Gatti</strong> (Conservatorio di Musica Giacomo Puccini)<br><strong>Giuseppe Ernandez</strong> (Conservatory of Trapani)<br><strong>Massimo Reina</strong> (Conservatory of Trapani)<br><a class="btn" href="music/SMC2024_music&sonicArt_id146.pdf">program notes</a></li>
</ul>
<p id="dinner"><strong>Conference Dinner</strong></p>
<p>The conference dinner will take place at Restaurante Fundação Dr. António Cupertino de Miranda, at Avenida da Boavista 4245, 4100-140 Porto. The <a href="https://www.stcp.pt/en/travel/lines/?linha=502&sentido=0&t=horarios">STCP BUS 502</a> goes directly from bus stop <em>Jornal de Notícias</em>, very close to ESMAE, to bus stop <em>Parque da Cidade</em>, very close to the restaurant.</p>
<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3003.6268439268756!2d-8.675855487248398!3d41.16449317120963!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0xd246f6fd6fa2ec5%3A0xf9c3d4ba398d7438!2sRestaurante%20da%20Funda%C3%A7%C3%A3o%20Cupertino%20de%20Miranda!5e0!3m2!1spt-PT!2spt!4v1719327080498!5m2!1spt-PT!2spt" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>
<section id="programme6" class="c"><div class="inner">
<div class="schedule_container">
  <table>
    <thead>
      <tr>
        <th class="none">July 6<sup>th</sup></th>
        <th class="none">Session</th>
        <th class="none">Place</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="hour">09h00</td>
        <td>Reception</td>
        <td>Entrance</td>
      </tr>
      <tr>
        <td class="hour">10h00</td>
        <td><a href="#paper6">Paper kick-off 6</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">11h00</td>
        <td><a href="#paper6">Poster/Demo 6</a></td>
        <td><em>coffee-break</em></td>
      </tr>
      <tr>
        <td class="hour">12h00</td>
        <td><a href="#concert3">Concert 3</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">13h00</td>
        <td><em>lunch</em></td>
        <td>Blackbox</td>
      </tr>
      <tr>
        <td class="hour">14h30</td>
        <td><a href="#keynote3">Keynote 3</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">15h30</td>
        <td><a href="#paper7">Paper kick-off 7</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">16h30</td>
        <td><a href="#paper7">Poster/Demo 7</a></td>
        <td><em>coffee-break</em></td>
      </tr>
      <tr>
        <td class="hour">17h30</td>
        <td><a href="#paper8">Paper kick-off 8</a></td>
        <td>Theatre</td>
      </tr>
      <tr>
        <td class="hour">18h30</td>
        <td><a href="#paper8">Poster/Demo 8</a></td>
        <td>Room 213</td>
      </tr>
      <tr>
        <td class="hour">19h30</td>
        <td><a href="#concert4">Closing & Concert 4</a></td>
        <td>Theatre</td>
      </tr>
    </tbody>
  </table>
</div>
<p id="paper6"><strong>Paper & Poster/Demo session 6</strong> July 6<sup>th</sup>, 10h00</p>
<ul>
  <li><em>Introducing MakamNetz – A Virtual Guide to Turkish Makam Universe</em><br><strong>Ozan Baysal</strong> (Istanbul Technical University)<br><strong>Recep Gül</strong> (Istanbul Technical University)<br><strong>Yusuf Can Şeftali</strong> (Istanbul Technical University)<br><strong>Gümrah Sindar</strong> (Istanbul Technical University)<br><strong>Zülfü Yalçın</strong> (Istanbul Technical University)<br><strong>Gözde Çolakoğlu Sarı</strong> (Istanbul Technical University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361336">paper</a><a class="btn" href="videos/SMC2024_video_id25.mp4">video</a></li>
  <li><em>Module-level MIDI</em><br><strong>Sean Luke</strong> (George Mason University)<br><strong>John Tuffen</strong> (wonkystuff)<br><strong>Mathias Brüssel</strong> (tangible waves)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361429">paper</a><a class="btn" href="videos/SMC2024_video_id84.mp4">video</a></li>
  <li><em>MIDI 1.5, So to Speak</em><br><strong>Sean Luke</strong> (George Mason University)<br><strong>Luca Ludovico</strong> (Università degli Studi di Milano)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361490">paper</a><a class="btn" href="videos/SMC2024_video_id85.mp4">video</a></li>
  <li><em>libremidi: a cross-platform library for real-time MIDI 1 and 2</em><br><strong>Jean-Michaël Celerier</strong> (Société des Arts Technologiques)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361546">paper</a><a class="btn" href="videos/SMC2024_video_id104.mp4">video</a></li>
  <li><em>Programming FPGA Platforms for Real-Time Audio Signal Processing in C++</em><br><strong>Pierre Cochard</strong> (Inria)<br><strong>Maxime Popoff</strong> (INSA Lyon)<br><strong>Romain Michon</strong> (Inria)<br><strong>Tanguy Risset</strong> (Insa-Lyon/Inria)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361591">paper</a><a class="btn" href="videos/SMC2024_video_id67.mp4">video</a></li>
  <li><em>Enabling Affordable and Scalable Audio Spatialization With Multichannel Audio Expansion Boards for FPGA</em><br><strong>Maxime Popoff</strong> (INSA Lyon)<br><strong>Romain Michon</strong> (Inria)<br><strong>Tanguy Risset</strong> (Insa-Lyon/Inria)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361660">paper</a><a class="btn" href="videos/SMC2024_video_id96.mp4">video</a></li>
  <li><em>Perspectives on Immersion Through Laser Doppler Vibrometry</em><br><strong>Roderick Buchanan-Dunlop</strong> (University of Edinburgh)<br><strong>Michael Newton</strong> (University of Edinburgh)<br><strong>Martin Parker</strong> (University of Edinburgh)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361722">paper</a><a class="btn" href="videos/SMC2024_video_id157.mp4">video</a></li>
  <li><em>Conditioning Methods for Neural Audio Effects</em><br><strong>Riccardo Simionato</strong> (Universirty of Oslo)<br><strong>Stefano Fasciani</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361773">paper</a><a class="btn" href="videos/SMC2024_video_id83.mp4">video</a></li>
</ul>
<p id="concert3"><strong>Concert 3</strong> July 6<sup>th</sup>, 12h00</p>
<ul>
  <li><em>les espaces negatifs</em><br><strong>Pierre Alexandre Tremblay</strong> (University of Huddersfield)<br><a class="btn" href="music/SMC2024_music&sonicArt_id48.pdf">program notes</a></li>
  <li><em>The Voices</em><br><strong>Ji Youn Kang</strong> (IEM, KUG Graz)<br><a class="btn" href="music/SMC2024_music&sonicArt_id108.pdf">program notes</a></li>
  <li><em>‘Rust’ for piano with subtle electronics</em><br><strong>Luís Neto da Costa</strong> (Aristotle University of Thessaloniki)<br><a class="btn" href="music/SMC2024_music&sonicArt_id232.pdf">program notes</a></li>
</ul>
<p id="paper7"><strong>Paper & Poster/Demo session 7</strong> July 6<sup>th</sup>, 15h30</p>
<ul>
  <li><em>Hybrid Neural Audio Effects</em><br><strong>Riccardo Simionato</strong> (Universirty of Oslo)<br><strong>Stefano Fasciani</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361819">paper</a><a class="btn" href="videos/SMC2024_video_id82.mp4">video</a></li>
  <li><em>Implementation of a Continuously Variable Delay Line by Crossfading Between Several Tap Delays</em><br><strong>Thibaut Carpentier</strong> (Ircam)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361885">paper</a><a class="btn" href="videos/SMC2024_video_id118.mp4">video</a></li>
  <li><em>Real-time Psychoacoustic Frequency Masking Compensation for Audio Signals with Overlapping Spectra</em><br><strong>Giorgio Presti</strong> (Università degli Studi di Milano)<br><strong>Nicola Degiorgi</strong> (Politecnico di Torino)<br><strong>Amedeo Fresia</strong> (Politecnico di Torino)<br><strong>Antonio Servetti</strong> (Politecnico di Torino)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361929">paper</a><a class="btn" href="videos/SMC2024_video_id126.mp4">video</a></li>
  <li><em>Modeling the Pultec EQP-1A with Wave Digital Filters</em><br><strong>Alberto Barrera</strong> (Universitat Pompeu Fabra)<br><strong>Xavier Lizarraga-Seijas</strong> (Music Technology Group Universitat Pompeu Fabra)<br><strong>Frederic Font</strong> (Music Technology Group Universitat Pompeu Fabra)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14361999">paper</a><a class="btn" href="videos/SMC2024_video_id132.mp4">video</a></li>
  <li><em>Revitalizing Multimedia Art: Restoration and Re-Activation of an Audiovisual Installation in Virtual Reality</em><br><strong>Alessandro Russo</strong> (University of Padua)<br><strong>Andrea Franceschini</strong> (Università di Padova)<br><strong>Antonio Rodà</strong> (University of Padova)<br><strong>Sergio Canazza</strong> (University of Padova)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362048">paper</a><a class="btn" href="videos/SMC2024_video_id29.mp4">video</a></li>
  <li><em>Music Theatre and Digital Archives</em><br><strong>Ana Filipa Gonçalves de Magalhães</strong> (CESEM NOVA FCSH)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362099">paper</a><a class="btn" href="videos/SMC2024_video_id24.mp4">video</a></li>
  <li><em>Phase Repair for Time-Domain Convolutional Neural Networks in Music Super-Resolution</em><br><strong>Yenan Zhang</strong> (Waseda University)<br><strong>Guilly Kolkman</strong> (University of Amsterdam,)<br><strong>Hiroshi Watanabe</strong> (Waseda University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362135">paper</a><a class="btn" href="videos/SMC2024_video_id44.mp4">video</a></li>
  <li><em>Flow: a Mutitimbral, Polyphonic, Modular, Additive Music Synthesizer</em><br><strong>Sean Luke</strong> (George Mason University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362177">paper</a><a class="btn" href="videos/SMC2024_video_id134.mp4">video</a></li>
  <li><em>Loom: a Speculation of Oral Tradition in Immersive Media</em><br><strong>Yingjia Guo</strong> (Stanford University)<br><strong>Mengtai Zhang</strong> (Fluffy Cactus)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362205">paper</a><a class="btn" href="videos/SMC2024_video_id175.mp4">video</a></li>
  <li><em>Exploring the Space Between Instrument and Controller</em><br><strong>Eleonora Oreggia</strong> (Goldsmiths)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362248">paper</a><a class="btn" href="videos/SMC2024_video_id252.mp4">video</a></li>
</ul>
<p id="paper8"><strong>Paper & Poster/Demo session 8</strong> July 6<sup>th</sup>, 17h30</p>
<ul>
  <li><em>Balancing Physical Modeling and Musical Requirements: Algorithmically Simulating the Calls of Hyalessa Maculaticollis for Real-time Instrumental Control</em><br><strong>Staas de Jong</strong> (Universiteit Leiden)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362425">paper</a><a class="btn" href="videos/SMC2024_video_id17.mp4">video</a></li>
  <li><em>A Universal Tool for Generating Datasets from Audio Effects</em><br><strong>Stefano Fasciani</strong> (University of Oslo)<br><strong>Riccardo Simionato</strong> (Universirty of Oslo)<br><strong>Aleksander Tidemann</strong> (University of Oslo)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362474">paper</a><a class="btn" href="videos/SMC2024_video_id28.mp4">video</a></li>
  <li><em>Stochastic Resonance: Molding Sounds from Noise</em><br><strong>Esteban A Gutiérrez</strong> (Pontificia Universidad Católica de Chile)<br><strong>Rodrigo F Cadiz</strong> (Pontificia Universidad Catolica de Chile)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14384378">paper</a><a class="btn" href="videos/SMC2024_video_id50.mp4">video</a></li>
  <li><em>Speculative Machine Learning in Sound Synthesis</em><br><strong>Luc Döbereiner</strong> (IEM, KUG Graz)<br><strong>David Pirrò</strong> (IEM, KUG Graz)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362528">paper</a><a class="btn" href="videos/SMC2024_video_id69.mp4">video</a></li>
  <li><em>Unveiling the Timbre Landscape: a Layered Analysis of Tenor Saxophone in RAVE Models</em><br><strong>Nádia Carvalho</strong> (University of Porto, Faculty of Engineering & INESC TEC)<br><strong>Jorge Sousa</strong> (University of Aveiro & INET-md)<br><strong>Gilberto Bernardes</strong> (INESC TEC & University of Porto, Faculty of Engineering)<br><strong>Henrique Portovedo</strong> (University of Aveiro)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362599">paper</a><a class="btn" href="videos/SMC2024_video_id91.mp4">video</a></li>
  <li><em>Tempo Estimation on Multiple Metrical Levels with Sequency Flux and Multiresolution Analysis</em><br><strong>Savvas Kazazis</strong> (Aristotle University of Thessaloniki)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362633">paper</a></li>
  <li><em>Correlations Between Objective and Subjective Evaluations of Music Source Separation</em><br><strong>Erika Rumbold</strong> (University of Victoria)<br><strong>George Tzanetakis</strong> (University of Victoria)<br><strong>Bryan Pardo</strong> (Northwestern University)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362681">paper</a><a class="btn" href="videos/SMC2024_video_id153.mp4">video</a></li>
  <li><em>Reconstructing the Charlie Parker Omnibook Using an Audio-to-score Automatic Transcription Pipeline</em><br><strong>Xavier Riley</strong> (C4DM)<br><strong>Simon Dixon</strong> (Queen Mary University of London)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362769">paper</a><a class="btn" href="videos/SMC2024_video_id154.mp4">video</a></li>
  <li><em>Exploring Deep Learning Methodologies for Music Emotion Recognition</em><br><strong>Pedro L. Louro</strong> (DEI FCTUC, University of Coimbra)<br><strong>Hugo Redinho</strong> (CISUC)<br><strong>Ricardo S Malheiro</strong> (CISUC / Polytechnic Institute of Leiria)<br><strong>Rui P Paiva</strong> (DEI FCTUC, University of Coimbra)<br><strong>Renato Panda</strong> (Ci2.ipt, CISUC)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362821">paper</a><a class="btn" href="videos/SMC2024_video_id182.mp4">video</a></li>
  <li><em>ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio</em><br><strong>Andrea Poltronieri</strong> (University of Bologna)<br><strong>Valentina Presutti</strong> (University of Bologna)<br><strong>Martín Rocamora</strong> (Universitat Pompeu Fabra)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362873">paper</a><a class="btn" href="videos/SMC2024_video_id205.mp4">video</a></li>
  <li><em>Prevalence Of Tresillo Rhythm In Contemporary Popular Music</em><br><strong>Pushkar Jajoria</strong> (University of Galway)<br><strong>Aurel Ruben Mäder</strong> (EPFL)<br><strong>James McDermott</strong> (University of Galway)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362917">paper</a><a class="btn" href="videos/SMC2024_video_id219.mp4">video</a></li>
</ul>
<p id="concert4"><strong>Concert 4</strong> July 6<sup>th</sup>, 19h30</p>
<ul>
  <li><em>saccades</em><br><strong>Ted Moore</strong><br><strong>Jorge Sousa</strong> (University of Aveiro, INET-md)<br><a class="btn" href="music/SMC2024_music&sonicArt_id12.pdf">program notes</a></li>
  <li><em>nan </em><br><strong>Ted Moore</strong><br><a class="btn" href="music/SMC2024_music&sonicArt_id13.pdf">program notes</a></li>
  <li><em>kurivari-live</em><br><strong>Alo Allik</strong> (tehis.net)<br><a class="btn" href="music/SMC2024_music&sonicArt_id209.pdf">program notes</a></li>
</ul>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="programmeOnline" class="d"><div class="inner">
<h3>Papers online only</h3>
<ul>
  <li><em>Design and Evaluation of Accessible Digital Musical Instruments for Pupils with Neurodevelopmental Disorders</em><br><strong>Matteo Olivo</strong> (Jean Monnet University of Saint-Etienne)<br><strong>Florence Carrouel</strong> (Health Systemic Process)<br><strong>Emily J Darlington</strong> (Université Claude Bernard Lyon 1)<br><strong>Laurent Pottier</strong> (CIEREC)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14362970">paper</a><a class="btn" href="videos/SMC2024_video_id105.mp4">video</a></li>
  <li><em>Biosensors in Immersive Music Performance: Andromeda for Flute and Biofeedback</em><br><strong>Penelope Bekiari</strong> (National and Kapodistrian University of Athens)<br><strong>Anastasia Georgaki</strong> (National and Kapodistrian University of Athens)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14363030">paper</a><a class="btn" href="videos/SMC2024_video_id106.mp4">video</a></li>
  <li><em>Xtrack: Automatic Segmentation of Live Music with YAMNet</em><br><strong>Florian Colombo</strong> (EPFL-UNIL)<br><strong>Alain Dufaux</strong> (EPFL)<br><strong>Davide Picca</strong> (University of Lausanne)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14363076">paper</a><a class="btn" href="videos/SMC2024_video_id125.mp4">video</a></li>
  <li><em>Cyborgutt: Exploring the body’s fluid boundaries through a biosensor composition</em><br><strong>Fotis Rovolis</strong> (National Kapodistrian University of Athens)<br><strong>Areti Andreopoulou</strong> (National and Kapodistrian University of Athens)<br><strong>Thanos Polymeneas Liontiris</strong> (National Kapodiatrian University of Athens)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14363129">paper</a><a class="btn" href="videos/SMC2024_video_id167.mp4">video</a></li>
  <li><em>Trajectory Descriptors: an Approach to Music Genre Classification through Curves and Vectors in the Tonnetz</em><br><strong>Christophe Weis</strong> (Hochschule für Musik Karlsruhe)<br><strong>Marlon Schumacher</strong> (Hochschule für Musik Karlsruhe)<br><strong>Moreno Andreatta</strong> (Université de Strasbourg)<br><a class="btn" href="https://doi.org/10.5281/zenodo.14363199">paper</a><a class="btn" href="videos/SMC2024_video_id178.mp4">video</a></li>
</ul>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="committees" class="a"><div class="inner">
<h3>Committees</h3>
<p><strong>Organising committee:</strong></p>
<ul>
<li><a href="https://angeladaponte.com/full-bio/">Ângela da Ponte</a> (ESMAE / CESEM), <strong>Music & Sonic Art co-chair / Summer School co-chair</strong></li>
<li><a href="https://dimitrisandrikopoulos.com/2020/01/01/about/">Dimitrios Andrikopoulos</a> (ESMAE / CESEM), <strong>Music & Sonic Art co-chair</strong></li>
<li><a href="https://sites.google.com/site/bernardes7/biography">Gilberto Bernardes</a> (FEUP / INESC TEC), <strong>Summer School co-chair</strong></li>
<li><a href="https://www.cienciavitae.pt//351F-A97A-8DA4">Guilherme Campos</a> (DETI-UA / IEETA), <strong>Paper co-chair</strong></li>
<li><a href="https://www.cienciavitae.pt/portal/5A1D-BFA1-CCFD">Inês Salselas</a> (ESMAE / CESEM), <strong>Paper co-chair</strong></li>
<li><a href="https://www.ua.pt/en/p/10311461">José Vieira</a> (DETI-UA / IEETA), <strong>Paper co-chair</strong></li>
<li><a href="https://www.cienciavitae.pt/portal/EE19-63EA-4A72">Marco Conceição</a> (ESMAE / CESEM), <strong>General chair</strong></li>
<li><a href="https://www.linkedin.com/in/nuno-fonseca-04250a30">Nuno Fonseca</a> (Sound Particles), <strong>Industry liaison chair</strong></li>
<li><a href="https://ruipenha.pt/about/">Rui Penha</a> (ESMAE / CESEM), <strong>Music & Sonic Art co-chair</strong></li>
</ul>
<p><strong>Scientific committee:</strong></p>
<ul class="noPadding">
<li>Akira Takaoka, J. F. Oberlin University</li>
<li>Alain Bonardi, CICM</li>
<li>Alex Chechile, RISD, SRST</li>
<li>Alexander Carôt, Anhalt University of Applied Science</li>
<li>Alexander Refsum, Jensenius, University of Oslo</li>
<li>Alexandros Kontogeorgakopoulos, NKUA </li>
<li>Andre Holzapfel, KTH Royal Institute of Technology in Stockholm</li>
<li>Andrew Horner, HKUST</li>
<li>Çağrı Erdem, University of Oslo</li>
<li>Carlos Guedes, NYU Abu Dhabi</li>
<li>Cat Hope, organization</li>
<li>Dan Overholt, Aalborg University Copenhagen</li>
<li>Daniel Hug, Zürcher Hochschule der Künste</li>
<li>Davide Fantini, University of Milan</li>
<li>Davide Rocchesso, Università di Palermo</li>
<li>Davide Andrea Mauro, Paderborn University</li>
<li>Diamantino Freitas, FEUP</li>
<li>Emanuel Sousa, CCG Institute</li>
<li>F. Amilcar Cardoso, University Coimbra</li>
<li>Federico Avanzini, University of Milan</li>
<li>Federico Simonetta, Gran Sasso Science Institute</li>
<li>Florence Leve, Université de Picardie Jules Verne Lab. MIS Algomus</li>
<li>Francesco Foscarin, Johannes Kepler University Linz</li>
<li>Frederico Pereira, CCG/ZGDV</li>
<li>Georg Essl, University of Wisconsin, Milwaukee</li>
<li>Georgios Marentakis, Østfold University College</li>
<li>Gerard Roma, University of Huddersfield</li>
<li>Gilberto Bernardes, FEUP / INESC TEC</li>
<li>Giorgio Gnecco, IMT School for Advanced Studies Lucca</li>
<li>Giorgio Presti, Università degli Studi di Milano</li>
<li>Giovanni Santini, Xi'an Jiaotong Liverpool</li>
<li>Grigore Burloiu, UNATC</li>
<li>Guilherme Campos, DETI UA</li>
<li>Hanna Järveläinen, Zurich University of the Arts</li>
<li>Hans Lindetorp, KMH</li>
<li>Haruhiro Katayose, Kwansei Gakuin Uniersity</li>
<li>Hiroki Nishino, Kochi University of Technology</li>
<li>Inês Salselas, ESMAE-IPP / CESEM</li>
<li>Jackson Loth, Queen Mary University of London</li>
<li>Jean-Louis Giavitto, STMS, CNRS IRCAM, Sorbonne Université</li>
<li>João Svidzinski, CICM</li>
<li>Johan Pauwels, Queen Mary University of London</li>
<li>Kjetil Falkenberg, KTH Sound and Music Computing Group</li>
<li>Leonardo Fierro, Aalto University</li>
<li>Luca Andrea Ludovico, University of Milan</li>
<li>Luna Valentim, CCRMA</li>
<li>Marcelo Queiroz, USP</li>
<li>Marco Conceição, ESMAE-IPP / CESEM</li>
<li>Martin  Ljungdahl Eriksson, University West</li>
<li>Matthew Davies, SiriusXM/Pandora</li>
<li>Maxime Popoff, INSA Lyon</li>
<li>Michael Boyd, Chatham University</li>
<li>Michael Mulshine, Stanford University</li>
<li>Michelle Lou, University of California, San Diego Cruz</li>
<li>Niccolo' Pretto, Free University of Bozen-Bolzano</li>
<li>Nicola Davanzo, Università degli Studi di Milano</li>
<li>Olivier Lartillot, RITMO, University of Oslo</li>
<li>Panayiotis Kokoras, University of North Texas</li>
<li>Pedro Rebelo, Queen's University Belfast</li>
<li>Pedro Pestana, Universidade Aberta</li>
<li>Pierre Jouvelot, MINES ParisTech</li>
<li>Pierre Alexandre Tremblay, University of Huddersfield</li>
<li>Raul Masu, CMA, HKUST-GZ</li>
<li>Riccardo Russo, University of Bologna</li>
<li>Roger Dannenberg, School of Computer Science, Carnegie Mellon University</li>
<li>Romain Michon, Inria</li>
<li>Rui Paiva, DEI FCTUC, University of Coimbra</li>
<li>Rui Penha, ESMAE / CESEM</li>
<li>Rumi Hiraga, Tsukuba University of Technology</li>
<li>Sebastian Schlecht, Aalto University</li>
<li>Shiguang Liu, Tianjin University</li>
<li>Stefania Serafin, Aalborg</li>
<li>Stefano D'Angelo, Orastron</li>
<li>Sylvain Marchand, La Rochelle University</li>
<li>Thibaut Carpentier, Ircam</li>
<li>Thomas Rushton, Inria</li>
<li>Tom Barker, Audiedge OU</li>
<li>Vanessa Faschi, Università degli Studi di Milano</li>
</ul>
<p><strong>Artistic committee:</strong></p>
<ul class="noPadding">
<li>Anastasia Georgaki, NKUA</li>
<li>Ângela da Ponte, ESMAE</li>
<li>Annie Mahtani, University of Birmingham</li>
<li>Arshia Samsaminia, Aristotle University of Thessaloniki, School of Music studies</li>
<li>Bruno Pereira, ESMAE P.PORTO</li>
<li>Carlos Guedes, NYU Abu Dhabi</li>
<li>Carlos Lopes, Freelance Composer</li>
<li>Dimitri Papageorgiou, Department of Music Studies, Aristotle University of Thessaloniki</li>
<li>Dimitris Andrikopoulos, ESMAE-IPP</li>
<li>Dimitris Maronidis, Aristotle University of Thessaloniki</li>
<li>Emma Margetson, University of Greenwich</li>
<li>Fani Kosona, Music School of Piraeus</li>
<li>Fátima Fonte, Guildhall School of Music and Drama</li>
<li>Filipe Lopes, CIPEM/INET-md</li>
<li>Francisca Goncalves, FEUP/ INESC-TEC</li>
<li>Henrique Ferreira, FEUP</li>
<li>Henrique Portovedo, University of Aveiro </li>
<li>Jaime Reis, ESML-IPL</li>
<li>Jorge Ramos, Independant</li>
<li>Jung In Jung, Abertay University</li>
<li>Konstantinos Vasilakos, XJTLU</li>
<li>Lorenda Ramou, University of Ioannina</li>
<li>Luís Bittencourt , Independent Artist-Researcher</li>
<li>Luís Costa, Aristotle University of Thessaloniki</li>
<li>Marco Conceicao, ESMAE-IPP / CESEM</li>
<li>Michalis Paraskakis, Aristotle University Thessaloniki Music Studies</li>
<li>Miguel Carvalhais, Faculty of Fine Arts, University of Porto</li>
<li>Notto Thelle, Oslo Metropolitan University</li>
<li>Nuno Peixoto de Pinho, ESMAE-IPP / ESE-IPP/ CIPEM/INET-md</li>
<li>Øyvind Brandtsegg, NTNU</li>
<li>Orestis Toufektsis, University of Music Graz</li>
<li>Øystein Fjeldbo, NTNU</li>
<li>Panayiotis Kokoras, University of North Texas</li>
<li>Pedro Rebelo, Queen's University Belfast</li>
<li>Pedro Pestana, Universidade Aberta</li>
<li>Romain Michon, Inria</li>
<li>Rui Dias, Polytechnic Universisty of Castelo Branco</li>
<li>Rui Penha, ESMAE / CESEM</li>
<li>Scott Wilson, University of Birmingham</li>
<li>Telmo Marques, ESMAE</li>
<li>Teresa Carrasco Garcia, HKB</li>
<li>Yota Morimoto, Waseda University</li>
</ul>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="location" class="b"><div class="inner">
<h3>Location</h3>
<p>The <strong>School of Music and Performing Arts (ESMAE)</strong> is a national and international reference for higher education in arts. Located in the centre of Porto, ESMAE has an international standing, and offers customised and cutting-edge higher education programmes in music and drama.</p>
<p>Built in 1985, on the foundations of the former School of Music, this is one of the founding schools of the Porto Polytechnic. Today it features two departments music and theatre and a postgraduate programme in Dance was created in 2016.</p>
<p> ESMAE is home to the Helena Sá e Costa Theatre and to the Café-Concert Francisco Beja, and apart from being a space for creating and experimenting, it is the venue of over 500 art events annually. The ESMAE Symphony Orchestra, the ESMAE Baroque Orchestra and the ESMAE Jazz Orchestra, among many others, are often the performers in many of those events.</p>
<div class="slider">
  <img class="slide" src="imagens/c01.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c02.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c03.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c04.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c05.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c06.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c07.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c08.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c09.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c10.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c11.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c12.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c13.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c14.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c15.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c16.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c17.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c18.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c19.jpg" alt="ESMAE">
  <img class="slide" src="imagens/c20.jpg" alt="ESMAE">
  <button class="button display-left" onclick="plusDivs(-1)">&#10094;</button>
  <button class="button display-right" onclick="plusDivs(+1)">&#10095;</button>
</div>
<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3004.0931974090986!2d-8.605882587698188!3d41.154317671210784!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0xd2464f089780a61%3A0xee108c715ecd9ae2!2sEscola%20Superior%20de%20M%C3%BAsica%20e%20Artes%20do%20Espet%C3%A1culo!5e0!3m2!1spt-PT!2spt!4v1698677972958!5m2!1spt-PT!2spt" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
<p><strong>Porto</strong> is the capital of the second largest metropolitan area in Portugal and one of Europe's leading city destinations. It is served by an international airport and is home of some of the major cultural, industrial and economic activities in Portugal.</p>
<iframe src="https://www.youtube.com/embed/qY6Sq8YpVls?si=qGujVEj60M9oYBvi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<p><strong>Hotels</strong></p>
<p><strong>Hotel das Virtudes *****</strong><br>
Code for 10% discount: <strong>SMC2024</strong><br>
for reservations until July 1<sup>st</sup>, applicable to bookings between June 30<sup>th</sup> and July 6<sup>th</sup><br>
<a href="https://www.hoteldasvirtudes.pt/">https://www.hoteldasvirtudes.pt/</a><p>
<p><strong>PortoBay Teatro ****</strong><br>
Code for 10% discount: <strong>WELCOME</strong><br>
<a href="http://www.portobay.pt/">http://www.portobay.pt/</a><p>
<p><strong>Hotel da Música ****</strong><br>
Code for 10% discount: <strong>SMC2024</strong><br>
<a href="https://www.hoteldamusica.com/">https://www.hoteldamusica.com/</a><p>
<p><strong>Legendary Porto ***</strong><br>
Code for 12% discount in booking and 5% in the hotel bar: <strong>CSMC</strong><br>
applicable to bookings between July 4<sup>th</sup> and July 8<sup>th</sup><br>
<a href="http://www.legendaryportohotel.com/">http://www.legendaryportohotel.com/</a><p>
<p><strong>Grupo HF (several hotels, with 3, 4 and 5 stars)</strong><br>
Link with 10% discount:</strong><br>
<a href="https://soundandmusiccomputing.hfhotels.com/">https://soundandmusiccomputing.hfhotels.com/</a><p>
<p><strong>Hostel Cats Porto</strong><br>
Code for 18% discount: <strong>SMCONF24</strong><br>
Alternatively, use this link for the same 18% discount:<br>
<a href="https://app.mews.com/distributor/2f0cc73a-9d73-4e6b-9fc4-45318f558c7c?mewsVoucherCode=SMCONF24">https://app.mews.com/distributor/2f0cc73a-9d73-4e6b-9fc4-45318f558c7c?mewsVoucherCode=SMCONF24</a><p>
<div class="toplink"><a href="#top">&uarr; Back to top of page</a></div>
</div></section>

<section id="logos">
  <div class="inner">
    <div class="row">
      <div class="column">
       <a href="https://www.esmae.ipp.pt"><img src="imagens/ESMAE.png" alt="ESMAE"></a>
     </div>
     <div class="column">
      <a href="https://www.ipp.pt"><img src="imagens/PPorto.png" alt="PPorto"></a>
    </div>
    <div class="column">
      <a href="https://cesem.fcsh.unl.pt"><img src="imagens/CESEM.png" alt="CESEM"></a>
    </div>
  </div>
  <div class="row">
    <div class="column">
      <a href="https://soundparticles.com"><img src="imagens/SP.png" alt="SP"></a>
    </div>
    <div class="column">
      <a href="https://www.ua.pt"><img src="imagens/UA.png" alt="UA"></a>
    </div>
    <div class="column">
      <a href="https://www.ieeta.pt"><img src="imagens/IEETA.png" alt="IEETA"></a>
    </div>
  </div>
  <div class="row">
    <div class="column">
      <a href="https://sigarra.up.pt/feup/pt/web_page.inicial"><img src="imagens/FEUP.png" alt="FEUP"></a>
    </div>
    <div class="column">
      <a href="https://www.inesctec.pt/en"><img src="imagens/INESCTEC.png" alt="INESCTEC"></a>
    </div>
    <div class="column">
      <a href="https://meyersound.com"><img src="imagens/MeyerSound.png" alt="Meyer Sound"></a>
    </div>
  </div>
  <div class="row">
    <div class="column">
      <a href="https://www.compete2030.gov.pt"><img src="imagens/C2030.png" alt="COMPETE2030"></a>
    </div>
    <div class="column">
      <a href="https://portugal2030.pt"><img src="imagens/PT2030.png" alt="PT2030"></a>
    </div>
    <div class="column">
      <a href="https://www.compete2030.gov.pt"><img src="imagens/UE.png" alt="UE"></a>
    </div>
  </div>
  </div>
</section>
</main>
</body>
<script>
var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("slide");
  if (n > x.length) {slideIndex = 1} 
  if (n < 1) {slideIndex = x.length} ;
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none"; 
  }
  x[slideIndex-1].style.display = "block"; 
}
</script>
</html>
